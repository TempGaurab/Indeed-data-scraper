{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2887fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1140c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this we copied the <div class=\"jobs-search__job-details--wrapper\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70e76ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_all(filename):\n",
    "    description = \"\"\n",
    "    with open(filename, \"r\", encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    # Extract title\n",
    "    h1_tag = soup.find('h1')\n",
    "    title = h1_tag.get_text(strip=True) if h1_tag else 'Not Found'\n",
    "\n",
    "    # Extract information from div with class 't-black--light mt2'\n",
    "    div_tag = soup.find('div', class_='t-black--light mt2')\n",
    "    if div_tag:\n",
    "        spans = div_tag.find_all('span', class_='tvm__text tvm__text--low-emphasis')\n",
    "        location = spans[0].get_text(strip=True) if len(spans) > 0 else 'Not Found'\n",
    "        date_posted = spans[2].get_text(strip=True) if len(spans) > 2 else 'Not Found'\n",
    "    else:\n",
    "        location = date_posted  = 'Not Found'\n",
    "\n",
    "    # Extract information from li element\n",
    "    li_tag = soup.find('li', class_='job-details-jobs-unified-top-card__job-insight job-details-jobs-unified-top-card__job-insight--highlight')\n",
    "    if li_tag:\n",
    "        spans = li_tag.find_all('span')\n",
    "        salary = spans[0].get_text(strip=True) if len(spans) > 0 else 'Not Found'\n",
    "        on_site = li_tag.find('span', class_='ui-label ui-label--accent-3 text-body-small').get_text(strip=True) if li_tag.find('span', class_='ui-label ui-label--accent-3 text-body-small') else 'Not Found'\n",
    "        full_time = li_tag.find_all('span', class_='job-details-jobs-unified-top-card__job-insight-view-model-secondary')[1].get_text(strip=True) if len(li_tag.find_all('span', class_='job-details-jobs-unified-top-card__job-insight-view-model-secondary')) > 1 else 'Not Found'\n",
    "    else:\n",
    "        salary = on_site = full_time = 'Not Found'\n",
    "\n",
    "    # Extract description from div with class 'mt4'\n",
    "    article_tag = soup.find('article', class_='jobs-description__container')\n",
    "    diiv = article_tag.find('div', class_='mt4')\n",
    "    for mt4_div in diiv:\n",
    "        text = mt4_div.get_text(strip=True, separator='\\n')\n",
    "        description += text + '\\n\\n'  # Add a double newline between sections for clarity\n",
    "\n",
    "    # Create a DataFrame\n",
    "    data = {\n",
    "        'Title': [title],\n",
    "        'Location': [location],\n",
    "        'Date Posted': [date_posted],\n",
    "        'Salary': [salary],\n",
    "        'On-site': [on_site],\n",
    "        'Full-time': [full_time],\n",
    "        'Description': [description]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e463aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date Posted</th>\n",
       "      <th>Salary</th>\n",
       "      <th>On-site</th>\n",
       "      <th>Full-time</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Developer</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>HybridMatches your job preferences, workplace ...</td>\n",
       "      <td>HybridMatches your job preferences, workplace ...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>\\n\\nJob Summary\\n\\n\\n\\nSkilled AI Developer wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Title        Location Date Posted  \\\n",
       "0  AI Developer  Birmingham, AL  1 week ago   \n",
       "\n",
       "                                              Salary  \\\n",
       "0  HybridMatches your job preferences, workplace ...   \n",
       "\n",
       "                                             On-site    Full-time  \\\n",
       "0  HybridMatches your job preferences, workplace ...  Entry level   \n",
       "\n",
       "                                         Description  \n",
       "0  \\n\\nJob Summary\\n\\n\\n\\nSkilled AI Developer wi...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all(\"individual_jobs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6d09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://www.linkedin.com/jobs/search/?currentJobId=3982088754&geoId=103644278&keywords=artificial%20intelligence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc4141fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"individual_jobs.txt\", \"r\") as file:\n",
    "    #content = file.read()\n",
    "#content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d6e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup = BeautifulSoup(content, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426502ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nh1_tag = soup.find('h1')\\ntitle = h1_tag.get_text(strip=True)\\ntitle\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "h1_tag = soup.find('h1')\n",
    "title = h1_tag.get_text(strip=True)\n",
    "title\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0136fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndiv_tag = soup.find('div', class_='t-black--light mt2')\\n\\n# Extract the text from each span\\nlocation = div_tag.find_all('span', class_='tvm__text tvm__text--low-emphasis')[0].get_text(strip=True)\\ndate_posted = div_tag.find_all('span', class_='tvm__text tvm__text--low-emphasis')[2].get_text(strip=True)\\napplicants = div_tag.find('span', class_='tvm__text tvm__text--positive').get_text(strip=True)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "div_tag = soup.find('div', class_='t-black--light mt2')\n",
    "\n",
    "# Extract the text from each span\n",
    "location = div_tag.find_all('span', class_='tvm__text tvm__text--low-emphasis')[0].get_text(strip=True)\n",
    "date_posted = div_tag.find_all('span', class_='tvm__text tvm__text--low-emphasis')[2].get_text(strip=True)\n",
    "applicants = div_tag.find('span', class_='tvm__text tvm__text--positive').get_text(strip=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d96e5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location,date_posted,applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bfa0e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Find the li element\\nli_tag = soup.find('li', class_='job-details-jobs-unified-top-card__job-insight job-details-jobs-unified-top-card__job-insight--highlight')\\n\\n# Extract the relevant information\\nsalary = li_tag.find_all('span')[0].get_text(strip=True)\\non_site = li_tag.find('span', class_='ui-label ui-label--accent-3 text-body-small').get_text(strip=True)\\nfull_time = li_tag.find_all('span', class_='job-details-jobs-unified-top-card__job-insight-view-model-secondary')[1].get_text(strip=True)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Find the li element\n",
    "li_tag = soup.find('li', class_='job-details-jobs-unified-top-card__job-insight job-details-jobs-unified-top-card__job-insight--highlight')\n",
    "\n",
    "# Extract the relevant information\n",
    "salary = li_tag.find_all('span')[0].get_text(strip=True)\n",
    "on_site = li_tag.find('span', class_='ui-label ui-label--accent-3 text-body-small').get_text(strip=True)\n",
    "full_time = li_tag.find_all('span', class_='job-details-jobs-unified-top-card__job-insight-view-model-secondary')[1].get_text(strip=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a1e43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary,on_site,full_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a802998b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndiiv = soup.find('div', class_='mt4')\\np_tags = diiv.findAll('p')\\np_tags\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "diiv = soup.find('div', class_='mt4')\n",
    "p_tags = diiv.findAll('p')\n",
    "p_tags\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa5bbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#description = '\\n'.join([p.get_text(strip=True) for p in p_tags])\n",
    "#description"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
